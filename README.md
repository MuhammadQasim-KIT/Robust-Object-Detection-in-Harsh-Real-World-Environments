# Robust Object Detection in Harsh Real-World Environments  
### Evaluating Perception Reliability with Visual & Quantitative Evidence

Modern autonomous and vision-driven systems rarely work in perfect environments.  
They operate in dust, fog, low visibility, motion, and noisy conditions â€” situations where perception reliability truly matters.

This project demonstrates how object detection performance **changes between clean and harsh environments**, using:
- YOLOv8 detection  
- Realistic environmental degradation simulation  
- Quantitative analysis  
- Clear visual validation  

It presents an **engineering-focused evaluation** rather than just a demo model â€” making it relevant for autonomous systems, robotics, and safety-critical AI.

---

## ğŸ¯ Objectives

This project answers a very practical question:

> **How does an object detection model behave when the real world becomes harsh and unreliable?**

Specifically, it:

âœ”ï¸ Runs object detection on a clean environment  
âœ”ï¸ Simulates harsh environmental conditions (fog, dust, blur, noise, low light)  
âœ”ï¸ Re-runs detection under degraded conditions  
âœ”ï¸ Measures detection stability and confidence  
âœ”ï¸ Visualizes and analyzes performance changes  

---

# ğŸ“¸ Visual Results

Below are visual demonstrations from the pipeline.

---

## ğŸ”¹ Baseline Detection (Normal Conditions)

Detection performance on the original, clean scene.

ğŸ¥ **Annotated Output Video**
results/videos/carss_yolo_baseline.mp4

![Baseline Example](data/raw/Raw.png)

---

## ğŸ”¹ Harsh Environment Simulation

The same scene was transformed to mimic real-world degradation such as:
- Fog / haze  
- Darkening  
- Dust particles  
- Motion blur  
- Sensor noise  

ğŸ¥ **Degraded Video**
data/processed/carss_degraded.mp4

![Degraded Example](data/processed/Degraded.png)

---

## ğŸ”¹ Detection in Harsh Conditions

ğŸ¥ **Annotated Degraded Detection Video**
results/videos/carss_degraded_yolo.mp4

Compared to the clean version:
- Fewer detected objects  
- More unstable bounding boxes  
- Lower visual confidence  

---

# ğŸ“Š Quantitative Evaluation

Beyond visuals, the project records detection statistics and evaluates numerically.

---

## ğŸ“Œ Detections Per Frame

![Detections Plot](results/plots/carss_detections_vs_frame.png)

**Insight**
- Clean video shows stable and consistent detections
- Harsh conditions significantly reduce detected objects
- Indicates missed vehicles / reduced awareness

---

## ğŸ“Œ Confidence Per Frame

![Confidence Plot](results/plots/carss_confidence_vs_frame.png)

**Insight**
- Confidence is high in clean conditions
- Under degradation, confidence fluctuates and drops
- Model becomes uncertain â†’ reduced reliability

---

## ğŸ“Œ Summary Metrics

### Average Detections Per Frame
![Average Detections](results/plots/carss_avg_detections_bar.png)

### Average Confidence
![Average Confidence](results/plots/carss_avg_confidence_bar.png)

---

# ğŸ§  Key Learnings

From both visual and numerical analysis:

âœ”ï¸ Detection quality **degrades significantly** in harsh environments  
âœ”ï¸ Both accuracy and confidence are affected  
âœ”ï¸ Perception becomes unstable and risky in safety-critical systems  

This highlights why real-world AI systems must focus on:

- Robustness
- Domain adaptation
- Multi-sensor fusion
- Real-world testing (not just benchmarks)

---

# ğŸ› ï¸ Technical Pipeline

1ï¸âƒ£ Baseline YOLO detection on clean video  
2ï¸âƒ£ Environmental degradation simulation  
3ï¸âƒ£ Re-run YOLO on degraded footage  
4ï¸âƒ£ Extract per-frame statistics  
5ï¸âƒ£ Generate comparison plots  
6ï¸âƒ£ Interpret engineering impact  

---

## ğŸ“‚ Project Structure

project/
 â”œâ”€ data/
 â”‚   â”œâ”€ raw/
 â”‚   â””â”€ processed/
 â”œâ”€ results/
 â”‚   â”œâ”€ videos/
 â”‚   â””â”€ plots/
 â”œâ”€ src/
 â””â”€ README.md

---

# ğŸš€ Applications

This kind of robustness analysis is critical for:

- Autonomous vehicles
- Robotics perception
- Industrial automation
- Smart safety systems
- Real-world ML deployment

---

# ğŸ Conclusion

This project demonstrates:

âœ”ï¸ Ability to build full AI pipelines  
âœ”ï¸ Focus on real-world reliability  
âœ”ï¸ Quantitative analytical thinking  
âœ”ï¸ Safety and engineering awareness  
âœ”ï¸ Clear communication of technical results  

It goes beyond â€œjust running a modelâ€ and instead focuses on **how AI behaves when the real world becomes difficult**.

---

# ğŸ‘¤ About

This project is part of my professional AI portfolio.
I am passionate about:

- Computer Vision  
- Robotics & Autonomous Systems  
- Real-world AI deployment  
- Reliability-focused engineering  

Feel free to explore, connect, or reach out ğŸ˜Š
